{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2360daa0",
   "metadata": {
    "id": "2360daa0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.regularizers import l2 \n",
    "from keras.models import Sequential, Model,load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee751d5",
   "metadata": {
    "direction": "ltr",
    "id": "df4eae57"
   },
   "source": [
    "## data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e588aa",
   "metadata": {
    "id": "42e588aa"
   },
   "outputs": [],
   "source": [
    "data = open('shahnameh.txt', 'r', encoding=\"utf8\").read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a146251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "2653849\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74cdfd15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74cdfd15",
    "outputId": "3e62341f-0f67-4f8c-b0c9-5609940a20a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique chars are:\n",
      " {'أ', ' ', 'ی', 'س', 'ض', 'ح', 'ه', 'م', 'خ', 'ف', '(', 'ٔ', 'غ', 'ت', '«', '؟', 'ل', 'ط', 'چ', 'ک', 'د', 'گ', 'پ', '|', 'ز', '»', 'ذ', 'ن', 'ب', 'آ', 'ئ', 'ع', ')', 'ا', 'ق', '\\n', 'ء', 'ث', '\\u200c', 'ؤ', 'و', 'ص', '،', 'ظ', 'ج', 'ر', 'ش', 'ژ'}\n"
     ]
    }
   ],
   "source": [
    "unique_chars = set(data)\n",
    "print('unique chars are:\\n', unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5d2d24",
   "metadata": {
    "id": "3f5d2d24"
   },
   "outputs": [],
   "source": [
    "vocab = sorted(unique_chars)\n",
    "vocab_size = len(vocab)\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}   # saving characters into a dictionary\n",
    "idx2char = np.array(vocab)                      # saving characters into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b8dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'\\n': 0, ' ': 1, '(': 2, ')': 3, '|': 4, '«': 5, '»': 6, '،': 7, '؟': 8, 'ء': 9, 'آ': 10, 'أ': 11, 'ؤ': 12, 'ئ': 13, 'ا': 14, 'ب': 15, 'ت': 16, 'ث': 17, 'ج': 18, 'ح': 19, 'خ': 20, 'د': 21, 'ذ': 22, 'ر': 23, 'ز': 24, 'س': 25, 'ش': 26, 'ص': 27, 'ض': 28, 'ط': 29, 'ظ': 30, 'ع': 31, 'غ': 32, 'ف': 33, 'ق': 34, 'ل': 35, 'م': 36, 'ن': 37, 'ه': 38, 'و': 39, 'ٔ': 40, 'پ': 41, 'چ': 42, 'ژ': 43, 'ک': 44, 'گ': 45, 'ی': 46, '\\u200c': 47}\n"
     ]
    }
   ],
   "source": [
    "print(type(char2idx))\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf99900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "['\\n' ' ' '(' ')' '|' '«' '»' '،' '؟' 'ء' 'آ' 'أ' 'ؤ' 'ئ' 'ا' 'ب' 'ت' 'ث'\n",
      " 'ج' 'ح' 'خ' 'د' 'ذ' 'ر' 'ز' 'س' 'ش' 'ص' 'ض' 'ط' 'ظ' 'ع' 'غ' 'ف' 'ق' 'ل'\n",
      " 'م' 'ن' 'ه' 'و' 'ٔ' 'پ' 'چ' 'ژ' 'ک' 'گ' 'ی' '\\u200c']\n"
     ]
    }
   ],
   "source": [
    "print(type(idx2char))\n",
    "print(idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66011d16",
   "metadata": {
    "id": "66011d16"
   },
   "outputs": [],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in data])    # integer-encoded dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388e5fed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "388e5fed",
    "outputId": "ce0df5de-43e0-493e-9af6-56bd68255009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2653849\n",
      "2653849\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(text_as_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28ade76c",
   "metadata": {
    "id": "28ade76c"
   },
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)      # char_dataset is an object holding dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2f237fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2f237fb",
    "outputId": "e6c170d4-034e-4a18-8970-ecb8c046aa18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2653849\n",
      "2653849\n"
     ]
    }
   ],
   "source": [
    "print(len(text_as_int))\n",
    "print(len(char_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92b1fac7",
   "metadata": {
    "id": "92b1fac7"
   },
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(10001, drop_remainder=True)             # seq_length = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b2963e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22b2963e",
    "outputId": "cafe8045-c2f6-4715-a766-c1303382f5e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)     # len(char_dataset)= 2653849  , seq_length = 1000   --->   int(2653849/1001) = 2651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad560e7",
   "metadata": {
    "id": "6ad560e7"
   },
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]         # to extract from index  0 to 999\n",
    "    target_text = sequence[1:]         # to extract from index  1 to 1000\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18f1658a",
   "metadata": {
    "id": "18f1658a"
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)   # X, Y  are in the \"dataset\" object!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a6ae926",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a6ae926",
    "outputId": "959aa8b2-0b65-4232-fcfb-2abb44c9030f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2057fb13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2057fb13",
    "outputId": "d9a466ea-ad24-4c5a-9d50-bdebd31a7fee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "for element in dataset:       # each element in the \"dataset\" is a tuple: (input_vector, output_vector) \n",
    "    \n",
    "    print(len(element))\n",
    "    \n",
    "    print( element[0].shape)  # input  ( 1000 x 1 ) vector \n",
    "    print( element[1].shape)  # output ( 1000 x 1 ) vector \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b484ddfe",
   "metadata": {
    "id": "b484ddfe"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000).batch(64, drop_remainder=True)       # BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b2efdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5b2efdb",
    "outputId": "a36c93c7-9ddf-4f22-bcec-89f8561230d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)    # len(sequences) = 2651  ,   BATCH_SIZE=64  ---->   int(2651/64) = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386ea969",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "386ea969",
    "outputId": "26f82283-02bd-44cc-bc97-ed1827d812b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(64, 10000)\n",
      "(64, 10000)\n",
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "for element in dataset:       # element(input_batch_matrix , output_batch_matrix)\n",
    "    \n",
    "    print(len(element))\n",
    "\n",
    "    print( element[0].shape)  # input   batch matrix : ( 64 x 1000 )\n",
    "    print( element[1].shape)  # output  batch matrix : ( 64 x 1000 )\n",
    "\n",
    "    print( element[0][5].shape)   # input  vector in the 5'th batch\n",
    "    print( element[1][38].shape)  # output vector in the 38'th batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f3b10",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "##### Up to this point, all the data has been converted into the required format for training the network and stored in the variable `dataset`. Both input and output data will be provided to the RNN in the form of 1000-dimensional vectors in batches of 64. Each element inside the input vectors corresponds to a numerical value representing a character. Since each character must be converted into a vector to be fed into the network, an embedding layer is added at the beginning of the RNN. We have set the `embedding_dim` parameter for the embedding layer to 256. This way, this layer will convert the numerical value of each input character into a vector in a 256-dimensional space. Then this 256-dimensional vector is input into 2 LSTM layers, followed by a dense layer that converts the output of the RNN into a 48-dimensional vector, equal to the total number of characters in the dataset. Each of the LSTM layers has 1024 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "203d8b6a",
   "metadata": {
    "id": "203d8b6a"
   },
   "outputs": [],
   "source": [
    "# vocab_length = 48\n",
    "# BATCH_SIZE = 64\n",
    "# embedding_dim = 256\n",
    "# seq_length = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e746ae9d",
   "metadata": {
    "id": "e746ae9d"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    \n",
    "  layers.Embedding( 48, 256, batch_input_shape=[64, None]),  # \"None\" has placed because input sequence can have differnet lengths!\n",
    "\n",
    "  layers.LSTM(1024,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform',recurrent_regularizer=keras.regularizers.l2(0.01)),\n",
    "  layers.LSTM(1024,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform',recurrent_regularizer=keras.regularizers.l2(0.01)),\n",
    "\n",
    "  layers.Dense(48)             \n",
    "\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9nyVUDMf1DhD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nyVUDMf1DhD",
    "outputId": "dd6792b6-7086-4c41-8d9d-1e94e6afea5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           12288     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 48)            49200     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,701,168\n",
      "Trainable params: 13,701,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "747803f2",
   "metadata": {
    "id": "747803f2"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd157812",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "cd157812",
    "outputId": "9c8b247e-afb0-4a8e-dace-1f60a3e8424a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "41/41 [==============================] - 75s 2s/step - loss: 13.4405 - accuracy: 0.1583\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 3.4817 - accuracy: 0.2226\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 2.7445 - accuracy: 0.2757\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 2.4732 - accuracy: 0.3047\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 2.3686 - accuracy: 0.3306\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 2.2943 - accuracy: 0.3483\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 2.2130 - accuracy: 0.3668\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 2.1434 - accuracy: 0.3818\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 2.0783 - accuracy: 0.3950\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 2.0213 - accuracy: 0.4093\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.9649 - accuracy: 0.4280\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.9114 - accuracy: 0.4429\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.8610 - accuracy: 0.4568\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.8139 - accuracy: 0.4701\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.7706 - accuracy: 0.4817\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.7286 - accuracy: 0.4937\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.7012 - accuracy: 0.5004\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.6621 - accuracy: 0.5113\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.6302 - accuracy: 0.5200\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.6024 - accuracy: 0.5275\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.5860 - accuracy: 0.5309\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.5553 - accuracy: 0.5404\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.5338 - accuracy: 0.5461\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.5149 - accuracy: 0.5510\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.4995 - accuracy: 0.5549\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.4820 - accuracy: 0.5596\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.4665 - accuracy: 0.5641\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.4529 - accuracy: 0.5677\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.4420 - accuracy: 0.5707\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.4277 - accuracy: 0.5752\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.4144 - accuracy: 0.5787\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.4032 - accuracy: 0.5816\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.3929 - accuracy: 0.5845\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.3827 - accuracy: 0.5877\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.3698 - accuracy: 0.5917\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.3605 - accuracy: 0.5942\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.3566 - accuracy: 0.5952\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.3428 - accuracy: 0.5991\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.3337 - accuracy: 0.6017\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.3251 - accuracy: 0.6045\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.3187 - accuracy: 0.6062\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.3102 - accuracy: 0.6086\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.3019 - accuracy: 0.6112\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.3000 - accuracy: 0.6117\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.2874 - accuracy: 0.6153\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.2807 - accuracy: 0.6173\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.2730 - accuracy: 0.6195\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 1.2662 - accuracy: 0.6215\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.2599 - accuracy: 0.6234\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.2544 - accuracy: 0.6251\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "Qe3Dt4BF-Q-a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "Qe3Dt4BF-Q-a",
    "outputId": "d445ba66-baf8-410a-d686-241332e4091e"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"650epochs.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "WG6wwfAB6iPS",
   "metadata": {
    "id": "WG6wwfAB6iPS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           12288     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 48)            49200     \n",
      "=================================================================\n",
      "Total params: 13,701,168\n",
      "Trainable params: 13,701,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07558a1c",
   "metadata": {
    "direction": "rtl",
    "id": "ww0fqzgJ-RIx"
   },
   "source": [
    "### To generate new data, we create a network similar to the one built for training. The difference is that we set the input dimensions to the size of a sequence instead of a batch size, because the input text to the network for generating verses will be in the form of a sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "_WufY7-J5vsc",
   "metadata": {
    "id": "_WufY7-J5vsc"
   },
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    \n",
    "  layers.Embedding(48, 256, batch_input_shape=[1, None]),\n",
    "\n",
    "  layers.LSTM(1024,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform',recurrent_regularizer=keras.regularizers.l2(0.01)),\n",
    "  layers.LSTM(1024,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform',recurrent_regularizer=keras.regularizers.l2(0.01)),\n",
    "\n",
    "  layers.Dense(48)             \n",
    "\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6zG-uOmv5vwN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zG-uOmv5vwN",
    "outputId": "c31da76c-fa23-40b4-9b7a-22cb86259edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            12288     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (1, None, 1024)           8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 48)             49200     \n",
      "=================================================================\n",
      "Total params: 13,701,168\n",
      "Trainable params: 13,701,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d79e0c6",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "### Transferring trained parameters to the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "yLm2ypOz5vt-",
   "metadata": {
    "id": "yLm2ypOz5vt-"
   },
   "outputs": [],
   "source": [
    "model2.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7152fbc0",
   "metadata": {
    "id": "7152fbc0"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string): \n",
    "    \n",
    "    # lets say the length of start_string is equal to \"L\"\n",
    " \n",
    "    # num_gen: number of characters to generate\n",
    "    num_gen = 1000\n",
    "\n",
    "    #---------------------------------------------------------------------------------------#\n",
    "    # input_eval here is a \"list\" of star_string character encoded numbers  \n",
    "    input_eval = [char2idx[s] for s in start_string] \n",
    "\n",
    "    # converting the input_eval list to a (1,L) tensorflow tensor as an input to the network\n",
    "    input_eval = tf.expand_dims(input_eval, 0) \n",
    "    #---------------------------------------------------------------------------------------#\n",
    "    # resetting LSTM cell memories   \n",
    "    model.reset_states()  \n",
    "    # ---------------------------------------------------------------------------------------#\n",
    "    # an empty list for saving ganerated texts\n",
    "    generated_text = []\n",
    "  #---------------------------------------------------------------------------------------#\n",
    "\n",
    "    for i in range(num_gen):\n",
    "        \n",
    "        # model output is a tensorflow tensor shaped ([1, L, 48])  \n",
    "        predictions = model(input_eval)   \n",
    "        \n",
    "        # turning the shape of the output tensor into ([L, 48])   \n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        #  drawing an independent sample from each row of output matrix(prediction)\n",
    "        #  and extracting the choosen element from the last row ( the last output of network )\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        # adding generated new character to the text\n",
    "        generated_text.append(idx2char[predicted_id])\n",
    "\n",
    "        # creating new input_eval with predicted_id in a tensorflow tensor shape as a new input to the network\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "  #---------------------------------------------------------------------------------------#\n",
    "    return (start_string + ''.join(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3933e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_poems = generate_text(model2, start_string=\"بدیشان چنین گفت پس شهریار\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ac348ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بدیشان چنین گفت پس شهریار\n",
      "|که با ایمنی شهنشاه یمن\n",
      "|که بیزارم از دل خویشتن\n",
      "|کنون باز پاسبان گرفتند\n",
      "|زمین چون قو بشنوده فسون\n",
      "|چودلش کرا به‌هم شاه انجمن\n",
      "|همی موی پاک یاد از مهر اوی\n",
      "|من این چادر قیصر اندکی\n",
      "|کشان و دل پر ز گور اندکی\n",
      "|نشد سست و او را به آواز نرم\n",
      "|چنین گفت با خاک و آب کردش کس\n",
      "|من این پادا میان را ببست\n",
      "|پذیرم من نیک نام او اردشیر\n",
      "|وگرنه بفرمود با سوار\n",
      "|مبادا که باشیم شاه و ترکان و چین\n",
      "|گسسته نبود ای سر ما زمان\n",
      "|که یابد نشانی زمان همی\n",
      "|از انجمن سخن تو پاکیزه‌رای\n",
      "|چو افگند سینه و کدخدای\n",
      "|به پهنای پادشاهی و راست\n",
      "|سه چرخ بلندگان ما\n",
      "|ز هندوستان بما نام تو\n",
      "|بفرمود تا به اژدها\n",
      "|نیامد به فرجام و تاج\n",
      "|خنک بودش آبگنگ ای سوار\n",
      "|چنین گوی کاین زهر آورد\n",
      "|بدان خواسته یک بار درخورد\n",
      "|سر آنکه ه سوگند خوار\n",
      "|همی پروراندهٔ روز ناسودمند\n",
      "|چنین پاسخ آوردش اسفندیار\n",
      "|که ای از توآمد همی با فسوس\n",
      "|سپاهم فرستد او را ببست\n",
      "|همان از پسشگفت یبدست\n",
      "|جهانی ببندوی او برید\n",
      "|سر چاه بن\n",
      "|پذیره شو و پهلوان سپاه\n",
      "|نخواهد ز منش و کاموس بود\n",
      "|جوان بود مر پاک دخدای\n",
      "|که دانا پیر سرافراز شاه\n",
      "|فراوان بلند ازین جاماسپ را\n",
      "|شنیدم که با مهتر جهان\n",
      "|که آن گور\n"
     ]
    }
   ],
   "source": [
    "print(rnn_poems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c93e38",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d71fa",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "### یکی از ابزارهای ارزیابی مدل های تولید کننده متن sentence_bleu می باشد\n",
    "### این ابزار دو متن را به عنوان ورودی گرفته و عددی بین 0 و 1 بر می گرداند. عدد تولید شده نشانگر میزان شباهت موجود میان دو متن می باشد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6478805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_poems = generate_text(model2, start_string=\"به نام خداوند جان و خرد\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a2ff4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n",
      "|نه از من چه آزردهٔ ماه اورند\n",
      "|بدو گفت گیو این سخن شهریار\n",
      "|پر اندیشه با ناله منست\n",
      "|برفت و بدین باز گشتی جهان\n",
      "|چنانش بدو ای دل پاک\n",
      "|ز خون ریختن با تو تافت\n",
      "|نه کشور چنین یکی ناسودمند\n",
      "|بگوی و خاک را بنهید روی\n",
      "|دوتا جهان از بد او یارتوان\n",
      "|بدین زور و این کاهلی\n",
      "|تو شو تیز خویشتن دیده‌ای\n",
      "|به گیتی جز از پهین داستان\n",
      "|نبودند کین از شیر آژیر بایدمی\n",
      "|که شد مغز ایشان فرخ نهیم\n",
      "|بپیش بزنار اندر از شرم\n",
      "|وزان پس که پایگها بشور بخواه\n",
      "|شگفتی بجوش آمد از کوه و دود\n",
      "|رخ مادر ار بدی تاب آورد که کشت\n",
      "|سزا و ز کیخسرو آغاز تو\n",
      "|چنین داد پاسخ که ای پهلوان\n",
      "|نباشد بدین ره تا باید گریست\n",
      "|چو آن گشت از ایرج آن تست\n",
      "|ز مهر ومایگاه آراستستی\n",
      "|نخواهد ز بخشش سر تاج زر\n",
      "|وگر هیچ دارید تا چه گونه نهنگ\n",
      "|ندانی همی تا بگرم نیکی بخواه\n",
      "|چو با سپه دد پادشاهی سپاه\n",
      "|ندیدم چون کین بود ایزدی\n",
      "|که بخشنده اویست و دستبرد\n",
      "|بوردم به آب داده اندر موبد\n",
      "|بدو گفت گستهم کای شهریار\n",
      "|شوم گفت مانامه بازجست\n",
      "|چنین است پیروزگر\n",
      "|پریچید گردن میان من\n",
      "|ز خویشان می پاسبان سپهر\n",
      "|بدو گفت گازر که از پهلوان\n",
      "|که با ما چون روانم پیشرو\n",
      "|تو دل را خراگنده تا دام\n",
      "|همه\n"
     ]
    }
   ],
   "source": [
    "print(rnn_poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82b849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0022502591251490176"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu(data[:1000] , rnn_poems, smoothing_function=SmoothingFunction().method2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
